"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[5835],{5709:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>c});var r=i(4848),a=i(8453);const s={title:"VLA Bibliography",sidebar_position:4},o="Vision-Language-Action Bibliography",l={id:"references/vla-bibliography",title:"VLA Bibliography",description:"This bibliography contains authoritative sources for Vision-Language-Action systems in robotics, formatted according to APA 7 standards.",source:"@site/docs/references/vla-bibliography.md",sourceDirName:"references",slug:"/references/vla-bibliography",permalink:"/Humanoid-AI-Book/docs/references/vla-bibliography",draft:!1,unlisted:!1,editUrl:"https://github.com/abdullatifjaffrani/Humanoid-AI-Book/tree/main/docs/references/vla-bibliography.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"VLA Bibliography",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Isaac Bibliography",permalink:"/Humanoid-AI-Book/docs/references/isaac-bibliography"},next:{title:"Humanoid Robotics Bibliography",permalink:"/Humanoid-AI-Book/docs/references/humanoid-bibliography"}},t={},c=[{value:"References",id:"references",level:2}];function d(n){const e={em:"em",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",...(0,a.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.h1,{id:"vision-language-action-bibliography",children:"Vision-Language-Action Bibliography"}),"\n",(0,r.jsx)(e.p,{children:"This bibliography contains authoritative sources for Vision-Language-Action systems in robotics, formatted according to APA 7 standards."}),"\n",(0,r.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Ahn, H., et al. (2022). Can language agents execute embodied natural language instructions through trial and error?. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2203.08578"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Ahn, M., et al. (2022). Do as i can, not as i say: Grounding language in robotic affordances. ",(0,r.jsx)(e.em,{children:"Conference on Robot Learning"}),", 82-94."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Agrawal, P., Nair, A. V., Chen, D., & Gupta, A. (2022). VLA: Vision-language-action models for embodied agents. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2206.00640"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. ",(0,r.jsx)(e.em,{children:"Advances in Neural Information Processing Systems"}),", 33, 1877-1901."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Brohan, A., et al. (2022). RT-1: Robotics transformer for real-world control at scale. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2208.01876"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Brohan, A., et al. (2023). RVT: Robotic view transformation for manipulation. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2304.07236"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Chen, H., et al. (2021). Behavior cloning from noisy, partially observed demonstrations via composite data augmentation. ",(0,r.jsx)(e.em,{children:"Conference on Robot Learning"}),", 102-114."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Chen, L., et al. (2023). VIMA: General robot manipulation with multimodal prompts. ",(0,r.jsx)(e.em,{children:"International Conference on Machine Learning"}),", 10447-10464."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Chen, X., et al. (2021). Decision transformer: Reinforcement learning via sequence modeling. ",(0,r.jsx)(e.em,{children:"Advances in Neural Information Processing Systems"}),", 34, 1508-1520."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., & Abbeel, P. (2016). Deep reinforcement learning from human preferences. ",(0,r.jsx)(e.em,{children:"Advances in Neural Information Processing Systems"}),", 29."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. ",(0,r.jsx)(e.em,{children:"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics"}),", 4171-4186."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Dosovitskiy, A., Springenberg, J. T., Firman, M., Brox, T., & Riedmiller, M. (2017). Learning to act by predicting the future. ",(0,r.jsx)(e.em,{children:"International Conference on Learning Representations"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Finn, C., Abbeel, P., & Levine, S. (2017). Model-agnostic meta-learning for fast adaptation of deep networks. ",(0,r.jsx)(e.em,{children:"International Conference on Machine Learning"}),", 1126-1135."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Hershey, S., Chaudhuri, S., Ellis, D. P., Gemmeke, J. F., Jansen, A., Moore, R. C., ... & Ritter, M. (2017). CNN architectures for large-scale audio classification. ",(0,r.jsx)(e.em,{children:"IEEE International Conference on Acoustics, Speech and Signal Processing"}),", 131-135."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Huang, S., et al. (2022). Inner monologue: Embodied reasoning through planning with language models. ",(0,r.jsx)(e.em,{children:"Conference on Robot Learning"}),", 535-548."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Huang, W., et al. (2022). Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. ",(0,r.jsx)(e.em,{children:"International Conference on Machine Learning"}),", 9158-9174."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., ... & Amodei, D. (2020). Scaling laws for neural language models. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2001.08361"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. ",(0,r.jsx)(e.em,{children:"Nature"}),", 521(7553), 436-444."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Levine, S., Pastor, P., Krizhevsky, A., & Quillen, D. (2016). Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. ",(0,r.jsx)(e.em,{children:"International Journal of Robotics Research"}),", 37(4-5), 421-436."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Lillicrap, T. P., Hunt, J. J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., ... & Wierstra, D. (2016). Continuous control with deep reinforcement learning. ",(0,r.jsx)(e.em,{children:"International Conference on Learning Representations"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Hassabis, D. (2015). Human-level control through deep reinforcement learning. ",(0,r.jsx)(e.em,{children:"Nature"}),", 518(7540), 529-533."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Nair, A., et al. (2018). Overcoming exploration in reinforcement learning with demonstrations. ",(0,r.jsx)(e.em,{children:"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}),", 6292-6299."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["OpenAI. (2020). Learning transferable visual models from natural language supervision. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2103.00020"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. ",(0,r.jsx)(e.em,{children:"Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics"}),", 2227-2237."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021). Learning transferable visual models from natural language supervision. ",(0,r.jsx)(e.em,{children:"International Conference on Machine Learning"}),", 8748-8763."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training. ",(0,r.jsx)(e.em,{children:"OpenAI"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., ... & Fei-Fei, L. (2015). ImageNet Large Scale Visual Recognition Challenge. ",(0,r.jsx)(e.em,{children:"International Journal of Computer Vision"}),", 115(3), 211-252."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). Proximal policy optimization algorithms. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1707.06347"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Shridhar, M., et al. (2022). Cliport: What and where pathways for robotic manipulation. ",(0,r.jsx)(e.em,{children:"Conference on Robot Learning"}),", 106-117."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., ... & Hassabis, D. (2016). Mastering the game of Go with deep neural networks and tree search. ",(0,r.jsx)(e.em,{children:"Nature"}),", 529(7587), 484-489."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. ",(0,r.jsx)(e.em,{children:"Journal of Machine Learning Research"}),", 15(1), 1929-1958."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction. MIT Press."}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. ",(0,r.jsx)(e.em,{children:"Advances in Neural Information Processing Systems"}),", 30."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Zeng, A., Mordatch, I., Florence, P., Welker, S., Tompson, J., Chou, P., ... & Lee, J. (2022). Socratic models: Composing zero-shot multimodal reasoning with language. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2207.05608"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., ... & Kiela, D. (2022). OPT: Open Pre-trained Transformer language models. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2205.01068"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Zhu, Y., et al. (2017). Target-driven visual navigation in indoor scenes using deep reinforcement learning. ",(0,r.jsx)(e.em,{children:"2017 IEEE international conference on robotics and automation (ICRA)"}),", 3357-3364."]}),"\n"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var r=i(6540);const a={},s=r.createContext(a);function o(n){const e=r.useContext(s);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),r.createElement(s.Provider,{value:e},n.children)}}}]);